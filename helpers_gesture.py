import cv2
import mediapipe as mp
import numpy as np

class HandDetector:
    def __init__(self, max_num_hands=1, detection_confidence=0.6, tracking_confidence=0.5):
        self.hands = mp.solutions.hands.Hands(
            static_image_mode=True,            # å–®å¼µåœ–ç‰‡è¼ƒç©©
            max_num_hands=max_num_hands,
            min_detection_confidence=detection_confidence,
            min_tracking_confidence=tracking_confidence,
        )
        self.drawer = mp.solutions.drawing_utils

    def detect(self, image):
        rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        result = self.hands.process(rgb)
        pts = None

        if result.multi_hand_landmarks:
            hand_landmarks = result.multi_hand_landmarks[0]
            h, w, _ = image.shape
            # ç”¨ã€Œæµ®é»åƒç´ åº§æ¨™ã€é¿å…æ•´æ•¸é™¤æ³•èª¤å·®
            pts = np.array([[lm.x * w, lm.y * h] for lm in hand_landmarks.landmark], dtype=np.float32)
            # ç•«é—œéµé»
            self.drawer.draw_landmarks(image, hand_landmarks, mp.solutions.hands.HAND_CONNECTIONS)

        return pts, image


class GestureRules:
    @staticmethod
    def classify(pts):
        """
        è¦å‰‡æ³•ï¼šTHUMB_UP / V / OK / UNKNOWN
        - ä»¥ã€Œå‚ç›´æ–¹å‘ã€åˆ¤æ–·æ‹‡æŒ‡æ˜¯å¦å‘ä¸Šï¼Œèˆ‡å·¦å³æ‰‹ç„¡é—œ
        - å…¶ä»–å››æŒ‡å…è¨±æœ€å¤š 1 æŒ‡ç¨å¾®ä¼¸ç›´ï¼ˆæ›´å¯¬é¬†ï¼‰
        """
        if pts is None:
            return "UNKNOWN"

        # æ‰‹æŒå°ºåº¦ï¼ˆé¿å…é è¿‘å·®ç•°ï¼‰
        wrist = pts[0]
        palm_scale = np.linalg.norm(pts[9] - wrist) + 1e-6  # wrist -> middle_mcp

        def extended_vertical(tip_idx, pip_idx, thr=0.08):
            """ tip åœ¨ pip ä¸Šæ–¹å¤šå°‘ï¼ˆy è¶Šå°è¶Šä¸Šæ–¹ï¼‰ï¼Œä»¥ palm_scale æ­£è¦åŒ– """
            tip, pip = pts[tip_idx], pts[pip_idx]
            return (pip[1] - tip[1]) / palm_scale > thr

        # å„æŒ‡æ˜¯å¦ä¼¸ç›´ï¼ˆä»¥å‚ç›´æ–¹å‘ç‚ºä¸»ï¼‰
        thumb_up    = (wrist[1] - pts[4][1]) / palm_scale > 0.12   # ğŸ‘ æ‹‡æŒ‡æ˜¯å¦ã€Œå‘ä¸Šã€(æ¯”æ‰‹è…•æ›´é«˜)
        index_ext   = extended_vertical(8, 6, 0.08)
        middle_ext  = extended_vertical(12,10, 0.08)
        ring_ext    = extended_vertical(16,14, 0.08)
        pinky_ext   = extended_vertical(20,18, 0.08)

        # OKï¼šæ‹‡æŒ‡å°–èˆ‡é£ŸæŒ‡å°–è·é›¢å¾ˆè¿‘ï¼ˆåœ“åœˆï¼‰
        ok_close = np.linalg.norm(pts[4] - pts[8]) / palm_scale < 0.18

        # ---- è¦å‰‡åˆ¤æ–·é †åºï¼šOK -> THUMB_UP -> V ----
        if ok_close:
            return "OK"

        # ğŸ‘ï¼šæ‹‡æŒ‡æ˜é¡¯ã€Œå‘ä¸Šã€ï¼Œå…¶ä»–å››æŒ‡ã€Œå¤§å¤šæœªä¼¸ç›´ã€ï¼ˆå…è¨±æœ€å¤š 1 æŒ‡ç¨ä¼¸ï¼‰
        if thumb_up:
            others_extended = sum([index_ext, middle_ext, ring_ext, pinky_ext])
            if others_extended <= 1:
                return "THUMB_UP"

        # âœŒï¸ï¼šé£ŸæŒ‡èˆ‡ä¸­æŒ‡ä¼¸ç›´ï¼Œç„¡åæŒ‡/å°æŒ‡æœªä¼¸ç›´
        if index_ext and middle_ext and not (ring_ext or pinky_ext):
            return "V"

        return "UNKNOWN"
